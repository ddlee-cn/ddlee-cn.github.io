<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Rendering &amp; Generative AI | LI, Jiacheng (Êùé ÂÆ∂‰∏û) </title> <meta name="author" content="Jiacheng LI"> <meta name="description" content="A research scientist with Sony Research, focusing on multimedia technology. "> <meta name="keywords" content="Jiacheng Li, Sony Research, Sony AI, Sony, USTC"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://ddlee-cn.github.io/rendering-&amp;-generative-ai/"> <script src="/assets/js/theme.js?a81d82887dd692e91686b43de4542f18"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav sticky-bottom-footer"> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> LI, Jiacheng (Êùé ÂÆ∂‰∏û) </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">Publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">Blog </a> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">Research </a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item " href="/computational-photography/">Computational Photography</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="/rendering-&amp;-generative-ai/">Rendering &amp; Genenerative AI</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="/streaming-&amp;-display/">Streaming &amp; Display</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="/intelligent-sensing/">Intelligent Sensing</a> </div> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Rendering &amp; Generative AI</h1> <p class="post-description"></p> </header> <article> <div class="post"> <article> <hr> <div class="profile float-left"> </div> <div class="clearfix"> <h2 id="toward-efficiency-neural-rendering">Toward Efficiency: Neural Rendering</h2> <p>A significant shift is underway in computer graphics, with traditional <a href="/blog/2024/CG-Pipeline/">rendering pipelines</a> being reimagined through novel computational architectures. Technologies like <a href="/blog/2025/DLSS4/">DLSS</a>, <a href="/blog/2022/AMD-FSR/">FSR</a>, and PSSR<sup id="fnref:PSSR"><a href="#fn:PSSR" class="footnote" rel="footnote" role="doc-noteref">1</a></sup> exemplify this trend, leveraging machine learning to break the long-standing trade-off between rendering cost and visual quality. My current research operates at this frontier, where I architect and integrate novel learning-based components directly into the rendering pipeline. The objective is to significantly boost both efficiency and visual fidelity for demanding applications, including real-time interactive graphics and scalable cloud-based rendering services.</p> <p><strong>References</strong></p> <div class="footnotes" role="doc-endnotes"> <ol> <li id="fn:PSSR"> <p><a href="https://www.playstation.com/en-us/ps5/ps5-pro/" rel="external nofollow noopener" target="_blank">PlayStation 5 Pro</a>¬†<a href="#fnref:PSSR" class="reversefootnote" role="doc-backlink">‚Ü©</a></p> </li> </ol> </div> </div> <hr> <div class="profile float-right"> </div> <div class="clearfix"> <h2 id="toward-creativity-image-editing">Toward Creativity: Image Editing</h2> <p>My exploration into generative AI and image editing commenced with a compelling challenge focused on Dunhuang Image Inpainting, part of the e-heritage workshop<sup id="fnref:iccv19"><a href="#fn:iccv19" class="footnote" rel="footnote" role="doc-noteref">1</a></sup> at ICCV 2019. The objective was to restore ancient paintings by filling in missing regions using an edge-guided contextual attention mechanism. Our team was honored with the <strong>WINNER</strong>üèÜ prize in this challenge.</p> <p>In the same year, the best paper award at ICCV 2019 for SinGAN<sup id="fnref:SinGAN"><a href="#fn:SinGAN" class="footnote" rel="footnote" role="doc-noteref">2</a></sup> captured my attention, particularly its novel approach to training Generative Adversarial Networks (GANs) on a single image without requiring paired data. This insight directly motivated my initial research project focused on leveraging single-image <strong>GANs</strong> to empower novel image editing capabilities. We conceptualized this work as <a href="/publications/#semantic%20image%20analogy">‚ÄúSemantic Image Analogy‚Äù</a>, a tribute to the foundational ‚ÄúImage Analogy‚Äù<sup id="fnref:IA"><a href="#fn:IA" class="footnote" rel="footnote" role="doc-noteref">3</a></sup> paper.</p> <p>Subsequently, my research delved deeper into understanding and leveraging spatial correlations within and between images. This led me to revisit inpainting with the <a href="/publications/#reference-guided">RefMatch</a> project, where we utilized reference images to extract fine-grained structural details for high-fidelity completion of missing regions. A distinctive aspect of was its reliance on pre-trained Deep Neural Networks (DNNs) solely as feature extractors, eschewing an explicit learning phase. Instead, pattern recognition was achieved through a <strong>multi-scale nearest neighbor search</strong> approach, which is kind of rebellious at that time when deep learning was dominating the field.</p> <p>Continuing this exploration of correlations, I initiated the <a href="/publications/#contextual%20outpainting">Contextual Outpainting</a> project. Here, I investigated the semantic relationships between different parts within an image, employing techniques such as <strong>VAEs</strong> (Variational Autoencoders) and <strong>Contrastive Learning</strong>. This line of inquiry has since been extended to incorporate later advancements like <strong>LoRA Adaptors</strong> and <strong>Stable Diffusion</strong> models. Additionally, I contributed to research on <a href="/publications/#region-aware%20portrait">image retouching</a> guided by sparse, interactive user instructions, a system that utilized <strong>cross-attention mechanisms</strong> and <strong>MoEs</strong> (Mixture of Experts).</p> <p>My experience also extends to utilizing single-step/few-step diffusion models for image enhancement, with a particular focus on facial images. Moving forward, my interest in this domain is expanding from the manipulation of 2D images to tackling the exciting challenges of generating and editing 3D assetsüé®.</p> <p><strong>References</strong></p> <div class="footnotes" role="doc-endnotes"> <ol> <li id="fn:iccv19"> <p><a href="https://www.cvl.iis.u-tokyo.ac.jp/e-Heritage2019/" rel="external nofollow noopener" target="_blank">ICCV Workshop on eHeritage</a>, 2019¬†<a href="#fnref:iccv19" class="reversefootnote" role="doc-backlink">‚Ü©</a></p> </li> <li id="fn:SinGAN"> <p><a href="https://tamarott.github.io/SinGAN.htm" rel="external nofollow noopener" target="_blank">Learning a Generative Model from a Single Natural Image</a>, in ICCV 2019¬†<a href="#fnref:SinGAN" class="reversefootnote" role="doc-backlink">‚Ü©</a></p> </li> <li id="fn:IA"> <p><a href="https://dl.acm.org/doi/10.1145/383259.383295" rel="external nofollow noopener" target="_blank">Image Analogies</a>, in SIGGPRAPH 2001¬†<a href="#fnref:IA" class="reversefootnote" role="doc-backlink">‚Ü©</a></p> </li> </ol> </div> </div> </article> </div> </article> </div> </div> <footer class="sticky-bottom mt-5" role="contentinfo"> <div class="container"> ¬© Copyright 2025 Jiacheng LI. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/assets/js/search-setup.js?6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/assets/js/search-data.js"></script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>